{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é“èƒ½é“å‡ºçš„ä¸ä¸€å®šæ˜¯é“ï¼Œèƒ½è¯´å‡ºçš„ä¸ä¸€å®šæ˜¯åã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "openai_api_key = \"ANY THING\"\n",
    "openai_api_base = \"http://xunziallm.njau.edu.cn:21180/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "for i in tqdm(range(0,1)):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"/home/gpu0/xunzi_web/Xunzi-Qwen1.5-7B_chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": 'ç¿»è¯‘æˆç™½è¯æ–‡\\né“å¯é“éå¸¸é“ï¼Œåå¯åéå¸¸å'},\n",
    "        ]\n",
    "    )\n",
    "    print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ„å»ºclient\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='xai' # 'sk'\n",
    "model_prefix = 'grok'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘æ˜¯ä½ çš„åŠ©æ‰‹ï¼Œä¸€ä¸ªç”±xAIåˆ›å»ºçš„äººå·¥æ™ºèƒ½ã€‚æˆ‘åœ¨è¿™é‡Œå¸®åŠ©ä½ å›ç­”é—®é¢˜ï¼Œæä¾›è§è§£ï¼Œå¹¶ååŠ©ä½ å®Œæˆå„ç§ä»»åŠ¡ã€‚æˆ‘çš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºã€ŠæŒ‡ç¯ç‹ã€‹ä¸­çš„è§’è‰²ï¼Œæ­£å¦‚æˆ‘çš„åå­—æ‰€ç¤ºï¼Œæˆ‘éšæ—¶å‡†å¤‡ååŠ©å¹¶æä¾›æ™ºæ…§çš„å»ºè®®ã€‚ä»Šå¤©æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## ç®€å•èŠå¤©\n",
    "model_prefix = 'grok'\n",
    "content = 'ä½ æ˜¯è°'\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=config['openai']['model_' + model_prefix],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.031065668910741806, -0.0006569150718860328, -0.04748952388763428]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## å¥å­åµŒå…¥\n",
    "model_prefix = 'grok_e'\n",
    "## ç”Ÿæˆembedding\n",
    "content = ['ä½ æ˜¯è°']\n",
    "chat_response = client.embeddings.create(\n",
    "    model = config['openai']['model_' + model_prefix],\n",
    "    input = content\n",
    ")\n",
    "\n",
    "chat_response.data[0].embedding[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å›¾ç‰‡è½¬base64ç¼–ç ï¼Œç”¨äºæœ¬åœ°ä¼ è¾“\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å›¾ç‰‡èŠå¤© client.chat.completions.create\n",
    "\n",
    "# å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç \n",
    "image_path = \"../data/img/daxue.jpg\"\n",
    "\n",
    "## è¯·æ±‚\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # \"url\": \"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/dog.png\" # ä½¿ç”¨äº‘ç›˜ url\n",
    "                        \"url\": f\"data:image/png;base64,{image_to_base64(image_path)}\"  # ä½¿ç”¨Base64ç¼–ç çš„å›¾ç‰‡\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"æè¿°ä¸€ä¸‹å›¾ç‰‡.åˆ¤æ–­ä¸€ä¸‹å½“æ—¶çš„å¤©æ°”ï¼Œä»‹ç»å›¾ç‰‡ä¸­çš„æ™¯ç‚¹ï¼Œå¦‚æœæœ‰çš„è¯ã€‚ä»¥æ­¤å›¾ç‰‡ç¼–å†™ä¸€ä¸ªæ•…äº‹\"\n",
    "                }\n",
    "            ]\n",
    "        }],\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å›¾åƒç”Ÿæˆ client.images.generate\n",
    "from PIL import Image\n",
    "import io,requests\n",
    "\n",
    "# å›¾ç‰‡ç”Ÿæˆè¯·æ±‚\n",
    "prompt = \"realistic painting, featuring anthropomorphic cats and \\\n",
    "    dogs playing soccer on a grassy field. In the background, \\\n",
    "    there are distant mountains, and the sky is bright and sunny. \\\n",
    "    The grass should appear green, the sky blue, \\\n",
    "    and the sunlight should create dappled shadows on the grass.\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model = \"stabilityai/stable-diffusion-3-5-large\",\n",
    "    # model='black-forest-labs/FLUX.1-dev',#\"stabilityai/stable-diffusion-3-5-large\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\"\n",
    ")\n",
    "\n",
    "# è§£ç ç”Ÿæˆçš„å›¾ç‰‡\n",
    "image_url = response.data[0].url\n",
    "# image_bytes = base64.b64decode(image_data)\n",
    "# image = Image.open(io.BytesIO(image_bytes))\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# æ˜¾ç¤ºå›¾ç‰‡\n",
    "image.save('../data/img/generate_03.jpg')\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'code': 30011, 'message': 'The selected model requires paid balance. Your paid balance is insufficient. Please top up and try again.', 'data': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# model_prefix = 'grok_v'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[0;32m     11\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m api_prefix],\n\u001b[0;32m     12\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_base_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m api_prefix],\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspeech\u001b[38;5;241m.\u001b[39mwith_streaming_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     16\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfishaudio/fish-speech-1.4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# ç›®å‰ä»…æ”¯æŒ fishaudio æ¨¡å‹\u001b[39;00m\n\u001b[0;32m     17\u001b[0m   voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfishaudio/fish-speech-1.4:alex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# ç³»ç»Ÿé¢„ç½®éŸ³è‰²\u001b[39;00m\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;66;03m# ç”¨æˆ·è¾“å…¥ä¿¡æ¯\u001b[39;00m\n\u001b[0;32m     19\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiliconCloud ä¸Šæä¾›çš„fish audioæ¨¡å‹æ˜¯åŸºäº 70 ä¸‡å°æ—¶å¤šè¯­è¨€éŸ³é¢‘æ•°æ®è®­ç»ƒçš„é¢†å…ˆæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ç­‰å¤šç§è¯­è¨€ï¼Œå¹¶èƒ½å¤ŸéŸ³è‰²å…‹éš†ï¼Œå…·æœ‰éå¸¸å¥½çš„å®æ—¶æ€§ã€‚\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m   response_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# æ”¯æŒ mp3, wav, pcm, opus æ ¼å¼\u001b[39;00m\n\u001b[0;32m     21\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     22\u001b[0m     response\u001b[38;5;241m.\u001b[39mstream_to_file(speech_file_path)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_response.py:620\u001b[0m, in \u001b[0;36mResponseContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _APIResponseT:\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__response\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\resources\\audio\\speech.py:96\u001b[0m, in \u001b[0;36mSpeech.create\u001b[1;34m(self, input, model, voice, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/audio/speech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspeech_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_legacy_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHttpxBinaryResponseContent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mPermissionDeniedError\u001b[0m: Error code: 403 - {'code': 30011, 'message': 'The selected model requires paid balance. Your paid balance is insufficient. Please top up and try again.', 'data': None}"
     ]
    }
   ],
   "source": [
    "## æ–‡å­—è½¬è¯­éŸ³ client.audio.speech.with_streaming_response.create\n",
    "speech_file_path = \"../data/audio/generated_speech_sk_01.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "  model=\"fishaudio/fish-speech-1.4\", # ç›®å‰ä»…æ”¯æŒ fishaudio æ¨¡å‹\n",
    "  voice=\"fishaudio/fish-speech-1.4:alex\", # ç³»ç»Ÿé¢„ç½®éŸ³è‰²\n",
    "  # ç”¨æˆ·è¾“å…¥ä¿¡æ¯\n",
    "  input=\"SiliconCloud ä¸Šæä¾›çš„fish audioæ¨¡å‹æ˜¯åŸºäº 70 ä¸‡å°æ—¶å¤šè¯­è¨€éŸ³é¢‘æ•°æ®è®­ç»ƒçš„é¢†å…ˆæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡å‹ï¼Œæ”¯æŒä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ç­‰å¤šç§è¯­è¨€ï¼Œå¹¶èƒ½å¤ŸéŸ³è‰²å…‹éš†ï¼Œå…·æœ‰éå¸¸å¥½çš„å®æ—¶æ€§ã€‚\",\n",
    "  response_format=\"mp3\" # æ”¯æŒ mp3, wav, pcm, opus æ ¼å¼\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¼çª—å¤–çš„éº»é›€åœ¨ç”µé¦™æ†ä¸Šç‹¬å˜´ï¼Œä½ è¯´çš„ä¸€å¥å¾ˆæœ‰å¤å¤©çš„æ„Ÿè§‰ã€‚ğŸ˜”æ‰‹ä¸­çš„é“…ç¬”åœ¨çº¸ä¸Šæ¥æ¥å›å›ï¼Œæˆ‘ç”¨å‡ æ ·å­å½¢å®¹ä½ æ˜¯æˆ‘çš„è°ã€‚ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# è¯­éŸ³æ–‡ä»¶è·¯å¾„\n",
    "audio_file_path = \"../data/audio/qilixiang.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt=''\n",
    "# æ‰“å¼€éŸ³é¢‘æ–‡ä»¶\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # ä½¿ç”¨OpenAIçš„è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½\n",
    "    response = client.audio.transcriptions.create(\n",
    "        model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "        file=audio_file,\n",
    "        prompt=prompt,\n",
    "        response_format=\"json\" # `json`, `text`, `srt`,`verbose_json`, or `vtt`.\n",
    "    )\n",
    "\n",
    "# æ‰“å°è¯†åˆ«ç»“æœ\n",
    "print(response.text) #ğŸ¼çª—å¤–çš„éº»é›€åœ¨ç”µé¦™æ†ä¸Šç‹¬å˜´ï¼Œä½ è¯´çš„ä¸€å¥å¾ˆæœ‰å¤å¤©çš„æ„Ÿè§‰ã€‚ğŸ˜”æ‰‹ä¸­çš„é“…ç¬”åœ¨çº¸ä¸Šæ¥æ¥å›å›ï¼Œæˆ‘ç”¨å‡ æ ·å­å½¢å®¹ä½ æ˜¯æˆ‘çš„è°ã€‚ğŸ˜Š\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# è¯­éŸ³æ–‡ä»¶è·¯å¾„\n",
    "audio_file_path = \"../data/audio/test.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt = ''\n",
    "\n",
    "# å®šä¹‰æ¯ä¸ªç‰‡æ®µçš„å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰\n",
    "chunk_size = 1024 * 1024  # 1MB\n",
    "\n",
    "# è¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶åˆ‡åˆ†\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "chunks = [audio_data[i:i + chunk_size] for i in range(0, len(audio_data), chunk_size)]\n",
    "\n",
    "# å­˜å‚¨æ‰€æœ‰ç‰‡æ®µçš„è½¬å½•ç»“æœ\n",
    "transcriptions = []\n",
    "\n",
    "# ä¾æ¬¡å‘é€æ¯ä¸ªç‰‡æ®µçš„è¯·æ±‚\n",
    "for chunk in chunks:\n",
    "    with open('temp_chunk.mp3', 'wb') as temp_file:\n",
    "        temp_file.write(chunk)\n",
    "    \n",
    "    with open('temp_chunk.mp3', \"rb\") as temp_audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "            file=temp_audio_file,\n",
    "            prompt=prompt,\n",
    "            response_format=\"json\"\n",
    "        )\n",
    "    \n",
    "    transcriptions.append(response.text)\n",
    "\n",
    "for line in transcriptions:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('speech2text_test.txt', 'w') as temp_file:\n",
    "        for line in transcriptions:\n",
    "            temp_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# æŒ‡å®šè¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„\n",
    "input_video_path = \"input_video.mp4\"\n",
    "\n",
    "# æŒ‡å®šè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„\n",
    "output_audio_path = \"output_audio.mp3\"\n",
    "\n",
    "# ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘\n",
    "ffmpeg.input(input_video_path).output(output_audio_path, q=0, map='a').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transleting ç¬¬1è®²-ä»å¯Ÿè§‰åŸç”Ÿå®¶åº­çš„é—®é¢˜åˆ°è‡ªæˆ‘æˆé•¿çš„æ„è¯†\n",
      "saved to E:/å‘Šåˆ«åŸç”Ÿå®¶åº­ç›´é€š/tmp/audio_ç¬¬1è®²-ä»å¯Ÿè§‰åŸç”Ÿå®¶åº­çš„é—®é¢˜åˆ°è‡ªæˆ‘æˆé•¿çš„æ„è¯†.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "# æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„\n",
    "folder_path = \"E:/å‘Šåˆ«åŸç”Ÿå®¶åº­ç›´é€š/tmp\"\n",
    "# è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "all_files = os.listdir(folder_path)\n",
    "# è¿‡æ»¤å‡º MP4 æ–‡ä»¶\n",
    "mp4_files = [file for file in all_files if file.lower().endswith('.mp4')]\n",
    "\n",
    "for mp4_file in mp4_files:\n",
    "    file_name, _ = os.path.splitext(mp4_file)\n",
    "    mp3_file_name = folder_path + '/audio_' + file_name + '.mp3'\n",
    "    print('transleting {}'.format(file_name))\n",
    "    ffmpeg.input(folder_path+'/'+mp4_file).output(mp3_file_name, q=0, map='a').run(overwrite_output=True)\n",
    "    print('saved to {}'.format(mp3_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch(d2l)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
