{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道能道出的不一定是道，能说出的不一定是名。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "openai_api_key = \"ANY THING\"\n",
    "openai_api_base = \"http://xunziallm.njau.edu.cn:21180/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "for i in tqdm(range(0,1)):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"/home/gpu0/xunzi_web/Xunzi-Qwen1.5-7B_chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": '翻译成白话文\\n道可道非常道，名可名非常名'},\n",
    "        ]\n",
    "    )\n",
    "    print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建client\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='xai' # 'sk'\n",
    "model_prefix = 'grok'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是你的助手，一个由xAI创建的人工智能。我在这里帮助你回答问题，提供见解，并协助你完成各种任务。我的设计灵感来自于《指环王》中的角色，正如我的名字所示，我随时准备协助并提供智慧的建议。今天有什么可以帮助你的吗？'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## 简单聊天\n",
    "model_prefix = 'grok'\n",
    "content = '你是谁'\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=config['openai']['model_' + model_prefix],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.031065668910741806, -0.0006569150718860328, -0.04748952388763428]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 句子嵌入\n",
    "model_prefix = 'grok_e'\n",
    "## 生成embedding\n",
    "content = ['你是谁']\n",
    "chat_response = client.embeddings.create(\n",
    "    model = config['openai']['model_' + model_prefix],\n",
    "    input = content\n",
    ")\n",
    "\n",
    "chat_response.data[0].embedding[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图片转base64编码，用于本地传输\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图片聊天 client.chat.completions.create\n",
    "\n",
    "# 将本地图片转换为Base64编码\n",
    "image_path = \"../data/img/daxue.jpg\"\n",
    "\n",
    "## 请求\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # \"url\": \"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/dog.png\" # 使用云盘 url\n",
    "                        \"url\": f\"data:image/png;base64,{image_to_base64(image_path)}\"  # 使用Base64编码的图片\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"描述一下图片.判断一下当时的天气，介绍图片中的景点，如果有的话。以此图片编写一个故事\"\n",
    "                }\n",
    "            ]\n",
    "        }],\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像生成 client.images.generate\n",
    "from PIL import Image\n",
    "import io,requests\n",
    "\n",
    "# 图片生成请求\n",
    "prompt = \"realistic painting, featuring anthropomorphic cats and \\\n",
    "    dogs playing soccer on a grassy field. In the background, \\\n",
    "    there are distant mountains, and the sky is bright and sunny. \\\n",
    "    The grass should appear green, the sky blue, \\\n",
    "    and the sunlight should create dappled shadows on the grass.\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model = \"stabilityai/stable-diffusion-3-5-large\",\n",
    "    # model='black-forest-labs/FLUX.1-dev',#\"stabilityai/stable-diffusion-3-5-large\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\"\n",
    ")\n",
    "\n",
    "# 解码生成的图片\n",
    "image_url = response.data[0].url\n",
    "# image_bytes = base64.b64decode(image_data)\n",
    "# image = Image.open(io.BytesIO(image_bytes))\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# 显示图片\n",
    "image.save('../data/img/generate_03.jpg')\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'code': 30011, 'message': 'The selected model requires paid balance. Your paid balance is insufficient. Please top up and try again.', 'data': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# model_prefix = 'grok_v'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[0;32m     11\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_key_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m api_prefix],\n\u001b[0;32m     12\u001b[0m     base_url\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapi_base_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m api_prefix],\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m client\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mspeech\u001b[38;5;241m.\u001b[39mwith_streaming_response\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     16\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfishaudio/fish-speech-1.4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# 目前仅支持 fishaudio 模型\u001b[39;00m\n\u001b[0;32m     17\u001b[0m   voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfishaudio/fish-speech-1.4:alex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# 系统预置音色\u001b[39;00m\n\u001b[0;32m     18\u001b[0m   \u001b[38;5;66;03m# 用户输入信息\u001b[39;00m\n\u001b[0;32m     19\u001b[0m   \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSiliconCloud 上提供的fish audio模型是基于 70 万小时多语言音频数据训练的领先文本到语音（TTS）模型，支持中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语等多种语言，并能够音色克隆，具有非常好的实时性。\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m   response_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp3\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# 支持 mp3, wav, pcm, opus 格式\u001b[39;00m\n\u001b[0;32m     21\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     22\u001b[0m     response\u001b[38;5;241m.\u001b[39mstream_to_file(speech_file_path)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_response.py:620\u001b[0m, in \u001b[0;36mResponseContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _APIResponseT:\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__response\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\resources\\audio\\speech.py:96\u001b[0m, in \u001b[0;36mSpeech.create\u001b[1;34m(self, input, model, voice, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/audio/speech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspeech_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_legacy_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHttpxBinaryResponseContent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\torch\\lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mPermissionDeniedError\u001b[0m: Error code: 403 - {'code': 30011, 'message': 'The selected model requires paid balance. Your paid balance is insufficient. Please top up and try again.', 'data': None}"
     ]
    }
   ],
   "source": [
    "## 文字转语音 client.audio.speech.with_streaming_response.create\n",
    "speech_file_path = \"../data/audio/generated_speech_sk_01.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "  model=\"fishaudio/fish-speech-1.4\", # 目前仅支持 fishaudio 模型\n",
    "  voice=\"fishaudio/fish-speech-1.4:alex\", # 系统预置音色\n",
    "  # 用户输入信息\n",
    "  input=\"SiliconCloud 上提供的fish audio模型是基于 70 万小时多语言音频数据训练的领先文本到语音（TTS）模型，支持中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语等多种语言，并能够音色克隆，具有非常好的实时性。\",\n",
    "  response_format=\"mp3\" # 支持 mp3, wav, pcm, opus 格式\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎼窗外的麻雀在电香杆上独嘴，你说的一句很有夏天的感觉。😔手中的铅笔在纸上来来回回，我用几样子形容你是我的谁。😊\n"
     ]
    }
   ],
   "source": [
    "# 语音文件路径\n",
    "audio_file_path = \"../data/audio/qilixiang.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt=''\n",
    "# 打开音频文件\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # 使用OpenAI的语音转文本功能\n",
    "    response = client.audio.transcriptions.create(\n",
    "        model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "        file=audio_file,\n",
    "        prompt=prompt,\n",
    "        response_format=\"json\" # `json`, `text`, `srt`,`verbose_json`, or `vtt`.\n",
    "    )\n",
    "\n",
    "# 打印识别结果\n",
    "print(response.text) #🎼窗外的麻雀在电香杆上独嘴，你说的一句很有夏天的感觉。😔手中的铅笔在纸上来来回回，我用几样子形容你是我的谁。😊\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 语音文件路径\n",
    "audio_file_path = \"../data/audio/test.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt = ''\n",
    "\n",
    "# 定义每个片段的大小（以字节为单位）\n",
    "chunk_size = 1024 * 1024  # 1MB\n",
    "\n",
    "# 读取音频文件并切分\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "chunks = [audio_data[i:i + chunk_size] for i in range(0, len(audio_data), chunk_size)]\n",
    "\n",
    "# 存储所有片段的转录结果\n",
    "transcriptions = []\n",
    "\n",
    "# 依次发送每个片段的请求\n",
    "for chunk in chunks:\n",
    "    with open('temp_chunk.mp3', 'wb') as temp_file:\n",
    "        temp_file.write(chunk)\n",
    "    \n",
    "    with open('temp_chunk.mp3', \"rb\") as temp_audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "            file=temp_audio_file,\n",
    "            prompt=prompt,\n",
    "            response_format=\"json\"\n",
    "        )\n",
    "    \n",
    "    transcriptions.append(response.text)\n",
    "\n",
    "for line in transcriptions:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('speech2text_test.txt', 'w') as temp_file:\n",
    "        for line in transcriptions:\n",
    "            temp_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# 指定输入视频文件路径\n",
    "input_video_path = \"input_video.mp4\"\n",
    "\n",
    "# 指定输出音频文件路径\n",
    "output_audio_path = \"output_audio.mp3\"\n",
    "\n",
    "# 使用 ffmpeg 提取音频\n",
    "ffmpeg.input(input_video_path).output(output_audio_path, q=0, map='a').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transleting 第1讲-从察觉原生家庭的问题到自我成长的意识\n",
      "saved to E:/告别原生家庭直通/tmp/audio_第1讲-从察觉原生家庭的问题到自我成长的意识.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "# 指定文件夹路径\n",
    "folder_path = \"E:/告别原生家庭直通/tmp\"\n",
    "# 获取文件夹中的所有文件\n",
    "all_files = os.listdir(folder_path)\n",
    "# 过滤出 MP4 文件\n",
    "mp4_files = [file for file in all_files if file.lower().endswith('.mp4')]\n",
    "\n",
    "for mp4_file in mp4_files:\n",
    "    file_name, _ = os.path.splitext(mp4_file)\n",
    "    mp3_file_name = folder_path + '/audio_' + file_name + '.mp3'\n",
    "    print('transleting {}'.format(file_name))\n",
    "    ffmpeg.input(folder_path+'/'+mp4_file).output(mp3_file_name, q=0, map='a').run(overwrite_output=True)\n",
    "    print('saved to {}'.format(mp3_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch(d2l)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
