{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é“èƒ½é“å‡ºçš„ä¸ä¸€å®šæ˜¯é“ï¼Œèƒ½è¯´å‡ºçš„ä¸ä¸€å®šæ˜¯åã€‚\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "openai_api_key = \"ANY THING\"\n",
    "openai_api_base = \"http://xunziallm.njau.edu.cn:21180/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "for i in tqdm(range(0,1)):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"/home/gpu0/xunzi_web/Xunzi-Qwen1.5-7B_chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": 'ç¿»è¯‘æˆç™½è¯æ–‡\\né“å¯é“éžå¸¸é“ï¼Œåå¯åéžå¸¸å'},\n",
    "        ]\n",
    "    )\n",
    "    print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## æž„å»ºclient\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='xai' # 'sk'\n",
    "model_prefix = 'grok'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æˆ‘æ˜¯ä½ çš„åŠ©æ‰‹ï¼Œä¸€ä¸ªç”±xAIåˆ›å»ºçš„äººå·¥æ™ºèƒ½ã€‚æˆ‘åœ¨è¿™é‡Œå¸®åŠ©ä½ å›žç­”é—®é¢˜ï¼Œæä¾›è§è§£ï¼Œå¹¶ååŠ©ä½ å®Œæˆå„ç§ä»»åŠ¡ã€‚æˆ‘çš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºŽã€ŠæŒ‡çŽ¯çŽ‹ã€‹ä¸­çš„è§’è‰²ï¼Œæ­£å¦‚æˆ‘çš„åå­—æ‰€ç¤ºï¼Œæˆ‘éšæ—¶å‡†å¤‡ååŠ©å¹¶æä¾›æ™ºæ…§çš„å»ºè®®ã€‚ä»Šå¤©æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## ç®€å•èŠå¤©\n",
    "model_prefix = 'grok'\n",
    "content = 'ä½ æ˜¯è°'\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=config['openai']['model_' + model_prefix],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.031065668910741806, -0.0006569150718860328, -0.04748952388763428]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## å¥å­åµŒå…¥\n",
    "model_prefix = 'grok_e'\n",
    "## ç”Ÿæˆembedding\n",
    "content = ['ä½ æ˜¯è°']\n",
    "chat_response = client.embeddings.create(\n",
    "    model = config['openai']['model_' + model_prefix],\n",
    "    input = content\n",
    ")\n",
    "\n",
    "chat_response.data[0].embedding[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å›¾ç‰‡è½¬base64ç¼–ç ï¼Œç”¨äºŽæœ¬åœ°ä¼ è¾“\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## å›¾ç‰‡èŠå¤© client.chat.completions.create\n",
    "\n",
    "# å°†æœ¬åœ°å›¾ç‰‡è½¬æ¢ä¸ºBase64ç¼–ç \n",
    "image_path = \"../data/img/daxue.jpg\"\n",
    "\n",
    "## è¯·æ±‚\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # \"url\": \"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/dog.png\" # ä½¿ç”¨äº‘ç›˜ url\n",
    "                        \"url\": f\"data:image/png;base64,{image_to_base64(image_path)}\"  # ä½¿ç”¨Base64ç¼–ç çš„å›¾ç‰‡\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"æè¿°ä¸€ä¸‹å›¾ç‰‡.åˆ¤æ–­ä¸€ä¸‹å½“æ—¶çš„å¤©æ°”ï¼Œä»‹ç»å›¾ç‰‡ä¸­çš„æ™¯ç‚¹ï¼Œå¦‚æžœæœ‰çš„è¯ã€‚ä»¥æ­¤å›¾ç‰‡ç¼–å†™ä¸€ä¸ªæ•…äº‹\"\n",
    "                }\n",
    "            ]\n",
    "        }],\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#å›¾åƒç”Ÿæˆ client.images.generate\n",
    "from PIL import Image\n",
    "import io,requests\n",
    "\n",
    "# å›¾ç‰‡ç”Ÿæˆè¯·æ±‚\n",
    "prompt = \"realistic painting, featuring anthropomorphic cats and \\\n",
    "    dogs playing soccer on a grassy field. In the background, \\\n",
    "    there are distant mountains, and the sky is bright and sunny. \\\n",
    "    The grass should appear green, the sky blue, \\\n",
    "    and the sunlight should create dappled shadows on the grass.\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model = \"stabilityai/stable-diffusion-3-5-large\",\n",
    "    # model='black-forest-labs/FLUX.1-dev',#\"stabilityai/stable-diffusion-3-5-large\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\"\n",
    ")\n",
    "\n",
    "# è§£ç ç”Ÿæˆçš„å›¾ç‰‡\n",
    "image_url = response.data[0].url\n",
    "# image_bytes = base64.b64decode(image_data)\n",
    "# image = Image.open(io.BytesIO(image_bytes))\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# æ˜¾ç¤ºå›¾ç‰‡\n",
    "image.save('../data/img/generate_03.jpg')\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# è¯»å–é…ç½®æ–‡ä»¶\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## æ–‡å­—è½¬è¯­éŸ³ client.audio.speech.with_streaming_response.create\n",
    "speech_file_path = \"../data/audio/generated_speech_sk_01.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "  model=\"fishaudio/fish-speech-1.4\", # ç›®å‰ä»…æ”¯æŒ fishaudio æ¨¡åž‹\n",
    "  voice=\"fishaudio/fish-speech-1.4:alex\", # ç³»ç»Ÿé¢„ç½®éŸ³è‰²\n",
    "  # ç”¨æˆ·è¾“å…¥ä¿¡æ¯\n",
    "  input=\"SiliconCloud ä¸Šæä¾›çš„fish audioæ¨¡åž‹æ˜¯åŸºäºŽ 70 ä¸‡å°æ—¶å¤šè¯­è¨€éŸ³é¢‘æ•°æ®è®­ç»ƒçš„é¢†å…ˆæ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰æ¨¡åž‹ï¼Œæ”¯æŒä¸­æ–‡ã€è‹±è¯­ã€æ—¥è¯­ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ã€éŸ©è¯­ã€é˜¿æ‹‰ä¼¯è¯­ç­‰å¤šç§è¯­è¨€ï¼Œå¹¶èƒ½å¤ŸéŸ³è‰²å…‹éš†ï¼Œå…·æœ‰éžå¸¸å¥½çš„å®žæ—¶æ€§ã€‚\",\n",
    "  response_format=\"mp3\" # æ”¯æŒ mp3, wav, pcm, opus æ ¼å¼\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¼çª—å¤–çš„éº»é›€åœ¨ç”µé¦™æ†ä¸Šç‹¬å˜´ï¼Œä½ è¯´çš„ä¸€å¥å¾ˆæœ‰å¤å¤©çš„æ„Ÿè§‰ã€‚ðŸ˜”æ‰‹ä¸­çš„é“…ç¬”åœ¨çº¸ä¸Šæ¥æ¥å›žå›žï¼Œæˆ‘ç”¨å‡ æ ·å­å½¢å®¹ä½ æ˜¯æˆ‘çš„è°ã€‚ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# è¯­éŸ³æ–‡ä»¶è·¯å¾„\n",
    "audio_file_path = \"../data/audio/qilixiang.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt=''\n",
    "# æ‰“å¼€éŸ³é¢‘æ–‡ä»¶\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # ä½¿ç”¨OpenAIçš„è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½\n",
    "    response = client.audio.transcriptions.create(\n",
    "        model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "        file=audio_file,\n",
    "        prompt=prompt,\n",
    "        response_format=\"json\" # `json`, `text`, `srt`,`verbose_json`, or `vtt`.\n",
    "    )\n",
    "\n",
    "# æ‰“å°è¯†åˆ«ç»“æžœ\n",
    "print(response.text) #ðŸŽ¼çª—å¤–çš„éº»é›€åœ¨ç”µé¦™æ†ä¸Šç‹¬å˜´ï¼Œä½ è¯´çš„ä¸€å¥å¾ˆæœ‰å¤å¤©çš„æ„Ÿè§‰ã€‚ðŸ˜”æ‰‹ä¸­çš„é“…ç¬”åœ¨çº¸ä¸Šæ¥æ¥å›žå›žï¼Œæˆ‘ç”¨å‡ æ ·å­å½¢å®¹ä½ æ˜¯æˆ‘çš„è°ã€‚ðŸ˜Š\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# è¯­éŸ³æ–‡ä»¶è·¯å¾„\n",
    "audio_file_path = \"../data/audio/test.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt = ''\n",
    "\n",
    "# å®šä¹‰æ¯ä¸ªç‰‡æ®µçš„å¤§å°ï¼ˆä»¥å­—èŠ‚ä¸ºå•ä½ï¼‰\n",
    "chunk_size = 1024 * 1024  # 1MB\n",
    "\n",
    "# è¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶åˆ‡åˆ†\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "chunks = [audio_data[i:i + chunk_size] for i in range(0, len(audio_data), chunk_size)]\n",
    "\n",
    "# å­˜å‚¨æ‰€æœ‰ç‰‡æ®µçš„è½¬å½•ç»“æžœ\n",
    "transcriptions = []\n",
    "\n",
    "# ä¾æ¬¡å‘é€æ¯ä¸ªç‰‡æ®µçš„è¯·æ±‚\n",
    "for chunk in chunks:\n",
    "    with open('temp_chunk.mp3', 'wb') as temp_file:\n",
    "        temp_file.write(chunk)\n",
    "    \n",
    "    with open('temp_chunk.mp3', \"rb\") as temp_audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "            file=temp_audio_file,\n",
    "            prompt=prompt,\n",
    "            response_format=\"json\"\n",
    "        )\n",
    "    \n",
    "    transcriptions.append(response.text)\n",
    "\n",
    "for line in transcriptions:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('speech2text_test.txt', 'w') as temp_file:\n",
    "        for line in transcriptions:\n",
    "            temp_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# æŒ‡å®šè¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„\n",
    "input_video_path = \"input_video.mp4\"\n",
    "\n",
    "# æŒ‡å®šè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„\n",
    "output_audio_path = \"output_audio.mp3\"\n",
    "\n",
    "# ä½¿ç”¨ ffmpeg æå–éŸ³é¢‘\n",
    "ffmpeg.input(input_video_path).output(output_audio_path, q=0, map='a').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transleting ç¬¬1è®²-ä»Žå¯Ÿè§‰åŽŸç”Ÿå®¶åº­çš„é—®é¢˜åˆ°è‡ªæˆ‘æˆé•¿çš„æ„è¯†\n",
      "saved to E:/å‘Šåˆ«åŽŸç”Ÿå®¶åº­ç›´é€š/tmp/audio_ç¬¬1è®²-ä»Žå¯Ÿè§‰åŽŸç”Ÿå®¶åº­çš„é—®é¢˜åˆ°è‡ªæˆ‘æˆé•¿çš„æ„è¯†.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "# æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„\n",
    "folder_path = \"E:/å‘Šåˆ«åŽŸç”Ÿå®¶åº­ç›´é€š/tmp\"\n",
    "# èŽ·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "all_files = os.listdir(folder_path)\n",
    "# è¿‡æ»¤å‡º MP4 æ–‡ä»¶\n",
    "mp4_files = [file for file in all_files if file.lower().endswith('.mp4')]\n",
    "\n",
    "for mp4_file in mp4_files:\n",
    "    file_name, _ = os.path.splitext(mp4_file)\n",
    "    mp3_file_name = folder_path + '/audio_' + file_name + '.mp3'\n",
    "    print('transleting {}'.format(file_name))\n",
    "    ffmpeg.input(folder_path+'/'+mp4_file).output(mp3_file_name, q=0, map='a').run(overwrite_output=True)\n",
    "    print('saved to {}'.format(mp3_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
