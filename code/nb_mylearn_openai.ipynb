{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道能道出的不一定是道，能说出的不一定是名。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "openai_api_key = \"ANY THING\"\n",
    "openai_api_base = \"http://xunziallm.njau.edu.cn:21180/v1\"\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "for i in tqdm(range(0,1)):\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"/home/gpu0/xunzi_web/Xunzi-Qwen1.5-7B_chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": '翻译成白话文\\n道可道非常道，名可名非常名'},\n",
    "        ]\n",
    "    )\n",
    "    print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建client\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='xai' # 'sk'\n",
    "model_prefix = 'grok'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是你的助手，一个由xAI创建的人工智能。我在这里帮助你回答问题，提供见解，并协助你完成各种任务。我的设计灵感来自于《指环王》中的角色，正如我的名字所示，我随时准备协助并提供智慧的建议。今天有什么可以帮助你的吗？'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## 简单聊天\n",
    "model_prefix = 'grok'\n",
    "content = '你是谁'\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=config['openai']['model_' + model_prefix],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.031065668910741806, -0.0006569150718860328, -0.04748952388763428]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 句子嵌入\n",
    "model_prefix = 'grok_e'\n",
    "## 生成embedding\n",
    "content = ['你是谁']\n",
    "chat_response = client.embeddings.create(\n",
    "    model = config['openai']['model_' + model_prefix],\n",
    "    input = content\n",
    ")\n",
    "\n",
    "chat_response.data[0].embedding[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图片转base64编码，用于本地传输\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 图片聊天 client.chat.completions.create\n",
    "\n",
    "# 将本地图片转换为Base64编码\n",
    "image_path = \"../data/img/daxue.jpg\"\n",
    "\n",
    "## 请求\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        # \"url\": \"https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/dog.png\" # 使用云盘 url\n",
    "                        \"url\": f\"data:image/png;base64,{image_to_base64(image_path)}\"  # 使用Base64编码的图片\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"描述一下图片.判断一下当时的天气，介绍图片中的景点，如果有的话。以此图片编写一个故事\"\n",
    "                }\n",
    "            ]\n",
    "        }],\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像生成 client.images.generate\n",
    "from PIL import Image\n",
    "import io,requests\n",
    "\n",
    "# 图片生成请求\n",
    "prompt = \"realistic painting, featuring anthropomorphic cats and \\\n",
    "    dogs playing soccer on a grassy field. In the background, \\\n",
    "    there are distant mountains, and the sky is bright and sunny. \\\n",
    "    The grass should appear green, the sky blue, \\\n",
    "    and the sunlight should create dappled shadows on the grass.\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model = \"stabilityai/stable-diffusion-3-5-large\",\n",
    "    # model='black-forest-labs/FLUX.1-dev',#\"stabilityai/stable-diffusion-3-5-large\",\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"1024x1024\",\n",
    "    response_format=\"url\"\n",
    ")\n",
    "\n",
    "# 解码生成的图片\n",
    "image_url = response.data[0].url\n",
    "# image_bytes = base64.b64decode(image_data)\n",
    "# image = Image.open(io.BytesIO(image_bytes))\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))\n",
    "\n",
    "# 显示图片\n",
    "image.save('../data/img/generate_03.jpg')\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### audio-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from openai import OpenAI\n",
    "\n",
    "# 读取配置文件\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "api_prefix='sk' # 'sk'\n",
    "client = OpenAI(\n",
    "    api_key=config['openai']['api_key_' + api_prefix],\n",
    "    base_url=config['openai']['api_base_' + api_prefix],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 文字转语音 client.audio.speech.with_streaming_response.create\n",
    "speech_file_path = \"../data/audio/generated_speech_sk_01.mp3\"\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "  model=\"fishaudio/fish-speech-1.4\", # 目前仅支持 fishaudio 模型\n",
    "  voice=\"fishaudio/fish-speech-1.4:alex\", # 系统预置音色\n",
    "  # 用户输入信息\n",
    "  input=\"SiliconCloud 上提供的fish audio模型是基于 70 万小时多语言音频数据训练的领先文本到语音（TTS）模型，支持中文、英语、日语、德语、法语、西班牙语、韩语、阿拉伯语等多种语言，并能够音色克隆，具有非常好的实时性。\",\n",
    "  response_format=\"mp3\" # 支持 mp3, wav, pcm, opus 格式\n",
    ") as response:\n",
    "    response.stream_to_file(speech_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎼窗外的麻雀在电香杆上独嘴，你说的一句很有夏天的感觉。😔手中的铅笔在纸上来来回回，我用几样子形容你是我的谁。😊\n"
     ]
    }
   ],
   "source": [
    "# 语音文件路径\n",
    "audio_file_path = \"../data/audio/qilixiang.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt=''\n",
    "# 打开音频文件\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # 使用OpenAI的语音转文本功能\n",
    "    response = client.audio.transcriptions.create(\n",
    "        model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "        file=audio_file,\n",
    "        prompt=prompt,\n",
    "        response_format=\"json\" # `json`, `text`, `srt`,`verbose_json`, or `vtt`.\n",
    "    )\n",
    "\n",
    "# 打印识别结果\n",
    "print(response.text) #🎼窗外的麻雀在电香杆上独嘴，你说的一句很有夏天的感觉。😔手中的铅笔在纸上来来回回，我用几样子形容你是我的谁。😊\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 语音文件路径\n",
    "audio_file_path = \"../data/audio/test.mp3\"\n",
    "# audio_file_path = \"../data/audio/i-know-kung-fu.mp3\"\n",
    "prompt = ''\n",
    "\n",
    "# 定义每个片段的大小（以字节为单位）\n",
    "chunk_size = 1024 * 1024  # 1MB\n",
    "\n",
    "# 读取音频文件并切分\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    audio_data = audio_file.read()\n",
    "\n",
    "chunks = [audio_data[i:i + chunk_size] for i in range(0, len(audio_data), chunk_size)]\n",
    "\n",
    "# 存储所有片段的转录结果\n",
    "transcriptions = []\n",
    "\n",
    "# 依次发送每个片段的请求\n",
    "for chunk in chunks:\n",
    "    with open('temp_chunk.mp3', 'wb') as temp_file:\n",
    "        temp_file.write(chunk)\n",
    "    \n",
    "    with open('temp_chunk.mp3', \"rb\") as temp_audio_file:\n",
    "        response = client.audio.transcriptions.create(\n",
    "            model=\"FunAudioLLM/SenseVoiceSmall\",\n",
    "            file=temp_audio_file,\n",
    "            prompt=prompt,\n",
    "            response_format=\"json\"\n",
    "        )\n",
    "    \n",
    "    transcriptions.append(response.text)\n",
    "\n",
    "for line in transcriptions:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('speech2text_test.txt', 'w') as temp_file:\n",
    "        for line in transcriptions:\n",
    "            temp_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "# 指定输入视频文件路径\n",
    "input_video_path = \"input_video.mp4\"\n",
    "\n",
    "# 指定输出音频文件路径\n",
    "output_audio_path = \"output_audio.mp3\"\n",
    "\n",
    "# 使用 ffmpeg 提取音频\n",
    "ffmpeg.input(input_video_path).output(output_audio_path, q=0, map='a').run(overwrite_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transleting 第1讲-从察觉原生家庭的问题到自我成长的意识\n",
      "saved to E:/告别原生家庭直通/tmp/audio_第1讲-从察觉原生家庭的问题到自我成长的意识.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "# 指定文件夹路径\n",
    "folder_path = \"E:/告别原生家庭直通/tmp\"\n",
    "# 获取文件夹中的所有文件\n",
    "all_files = os.listdir(folder_path)\n",
    "# 过滤出 MP4 文件\n",
    "mp4_files = [file for file in all_files if file.lower().endswith('.mp4')]\n",
    "\n",
    "for mp4_file in mp4_files:\n",
    "    file_name, _ = os.path.splitext(mp4_file)\n",
    "    mp3_file_name = folder_path + '/audio_' + file_name + '.mp3'\n",
    "    print('transleting {}'.format(file_name))\n",
    "    ffmpeg.input(folder_path+'/'+mp4_file).output(mp3_file_name, q=0, map='a').run(overwrite_output=True)\n",
    "    print('saved to {}'.format(mp3_file_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
