{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2228bc-24d1-4e7a-a793-4885b5774398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T09:21:28.207347Z",
     "iopub.status.busy": "2024-11-06T09:21:28.207347Z",
     "iopub.status.idle": "2024-11-06T09:21:49.985044Z",
     "shell.execute_reply": "2024-11-06T09:21:49.983914Z",
     "shell.execute_reply.started": "2024-11-06T09:21:28.207347Z"
    }
   },
   "outputs": [],
   "source": [
    "import myRNN_data as mrdata\n",
    "import myRNN_model as mrmodel\n",
    "import myRNN_pipline as mrpipl\n",
    "import myS2S_pipline as mspipl\n",
    "import torch,math,collections\n",
    "import torch.nn as nn\n",
    "from d2l import torch as d2l\n",
    "import os,logging\n",
    "# import matplotlib.pyplot as plt\n",
    "LOG_FORMAT = \"%(asctime)s-%(levelname)s-%(message)s\"\n",
    "logging.basicConfig(filename='./log/log.log', level=logging.INFO, format=LOG_FORMAT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73998b30-cd61-4d75-8444-9c48ced7fcea",
   "metadata": {},
   "source": [
    "## 训练S2S模型-机器翻译数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4668967e-265c-4cf0-9516-ff9fa04ba34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T09:27:22.428858Z",
     "iopub.status.busy": "2024-11-06T09:27:22.428858Z",
     "iopub.status.idle": "2024-11-06T09:27:22.435447Z",
     "shell.execute_reply": "2024-11-06T09:27:22.435447Z",
     "shell.execute_reply.started": "2024-11-06T09:27:22.428858Z"
    }
   },
   "outputs": [],
   "source": [
    "## 普通seq2seq\n",
    "# model_path = './saved_models/nmt_eng2fra_s2s_pure'\n",
    "# batch_size, num_steps = 64, 16\n",
    "# embed_size, num_hiddens, num_layers, dropout = 128, 128, 2, 0.2\n",
    "# incellplot = False\n",
    "# epoch = 100\n",
    "# num_examples = 100000 # 100000\n",
    "# device = d2l.try_gpu()\n",
    "# # model_path = train_pipline(model_path, batch_size, num_steps,\n",
    "# #                            embed_size, num_hiddens, num_layers,\n",
    "# #                            dropout,num_epochs=epoch, num_examples=num_examples, incellplot=incellplot)\n",
    "# model_path = './saved_models/nmt_eng2fra_s2s_pure_bz64_ns16_dime128_dimh128_nl2_epo100_lr0.01_10w.pkl'\n",
    "# mspipl.pridict_pipline(model_path, batch_size, num_steps, embed_size, num_hiddens, num_layers, dropout, device, num_examples=num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17503a37-c9c2-4967-9709-d9697e3ed8a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T09:21:54.151080Z",
     "iopub.status.busy": "2024-11-06T09:21:54.151080Z",
     "iopub.status.idle": "2024-11-06T09:21:54.158096Z",
     "shell.execute_reply": "2024-11-06T09:21:54.157975Z",
     "shell.execute_reply.started": "2024-11-06T09:21:54.151080Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.debug(\"This is a debug log.\")\n",
    "logging.info(\"This is a info log.\")\n",
    "logging.warning(\"This is a warning log.\")\n",
    "logging.error(\"This is a error log.\")\n",
    "logging.critical(\"This is a critical log.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d53ac90-acda-41bc-aac6-17b8fdda49e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-02T16:09:10.860747Z",
     "iopub.status.busy": "2024-11-02T16:09:10.860747Z",
     "iopub.status.idle": "2024-11-02T16:09:10.945554Z",
     "shell.execute_reply": "2024-11-02T16:09:10.945554Z",
     "shell.execute_reply.started": "2024-11-02T16:09:10.860747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/fra-eng/fra_preprocessed.txt exists, loading...\n"
     ]
    }
   ],
   "source": [
    "train_iter, src_vocab, tgt_vocab, _, _ = mrdata.load_data_nmt(32, 10, num_examples=1000, is_split=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf0f28-f078-4a25-9c0a-e1aa5208c5c1",
   "metadata": {},
   "source": [
    "## seq2seq attention 机制中实现attention 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68eb83b-3cd7-4f62-8c42-abaa71ca6648",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Attention 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84d258-449e-48bd-887a-74f1ed80a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对seq2seq的数据结构，实现注意力机制\n",
    "\n",
    "# input arg: X, size = [batch_size, seq_len]\n",
    "# input arg: en_outputs, size = [seq_len, batch_size, dim_hiddens]\n",
    "# input arg: state, size = [num_layer *  num_direction, batch_size, dim_hiddens]\n",
    "# input arg: x_vare_len, size = [batch_size]\n",
    "X = self.emb(X).permute(1, 0, 2) # emb并调整维度顺序后 [seq_len, batch_size, dim_emb]\n",
    "\n",
    "### attention\n",
    "# Q = state; K = en_outputs; V = en_outputs\n",
    "# res = F.softmax(Q.permute(1,0,2).matmul(K.permute(1,2,0))/math.sqrt(K.shape[-1])).matmul(K.permute(1,0,2))\n",
    "# dim res = (batch_size, 1, dim_hiddens)\n",
    "# 主要是维度变换的问题 对于批量矩阵相乘 只要保证前几维度相同即可自动计算后续例如size=(6,5,3,4) 和 size=(6,5,4,1)矩阵相乘得到(6,5,3,1)\n",
    "atte_scores = state.permute(1,0,2).matmul(en_outputs.permute(1,2,0))\n",
    "# 计算softmax分数\n",
    "atte_scores = F.softmax(atte_scores/math.sqrt(en_outputs.shape[-1]), dim=-1)\n",
    "atten_res = atte_scores.matmul(en_outputs.permute(1,0,2)).squeeze(1)\n",
    "context = atten_res.repeat(X.shape[0], 1, 1)\n",
    "# after cat size = [seq_len, batch_size, dim_hiddens + dim_emb]\n",
    "X_and_context = torch.cat((X, context), 2)\n",
    "output, state = self.rnn(X_and_context, state)\n",
    "output = self.dense(output).permute(1, 0, 2)\n",
    "# output的形状:(batch_size, num_steps, vocab_size)\n",
    "# state的形状: (num_layers * num_direction, batch_size, num_hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8a1505-2da0-45cc-b660-8efee462d454",
   "metadata": {},
   "source": [
    "### mask-softmax方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "170b3619-da87-4ba0-a7c2-8f11e179258d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T10:23:51.900345Z",
     "iopub.status.busy": "2024-11-06T10:23:51.899348Z",
     "iopub.status.idle": "2024-11-06T10:23:51.907108Z",
     "shell.execute_reply": "2024-11-06T10:23:51.907108Z",
     "shell.execute_reply.started": "2024-11-06T10:23:51.900345Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_softmax_my(score, valid_lens):\n",
    "    # score: (batch_size, 1, seq_len)\n",
    "    # valid_lens: (batch_size)\n",
    "    if len(valid_lens)<=0:\n",
    "        return softmax(score, dim=-1)\n",
    "    batch_size, num_layers, seq_len = score.shape\n",
    "    mat_valid = torch.Tensor(valid_lens).repeat(seq_len,1,1).permute(2,1,0)\n",
    "    mat_arrage = torch.arange(seq_len).repeat(batch_size,1,1)\n",
    "    score[mat_arrage>=mat_valid]=-1e6\n",
    "    score = nn.functional.softmax(score, dim=-1)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ea269-1c0f-4145-9a73-9d7b07977a86",
   "metadata": {},
   "source": [
    "### 训练seq2seq attention模型-翻译数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3302ad-aaa3-49c5-aa1c-c39796603efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = './saved_models/nmt_eng2fra_s2s_atten'\n",
    "# batch_size, num_steps = 64, 16\n",
    "# embed_size, num_hiddens, num_layers, dropout = 128, 128, 2, 0.2\n",
    "# incellplot = False\n",
    "# epoch = 100\n",
    "# num_examples = 10000\n",
    "# device = d2l.try_gpu()\n",
    "# model_path = train_s2s_attention_pipline(model_path, batch_size, num_steps,\n",
    "#                            embed_size, num_hiddens, num_layers,\n",
    "#                            dropout,num_epochs=epoch, num_examples=num_examples, incellplot=incellplot)\n",
    "# model_path = './saved_models/nmt_eng2fra_s2s_atten_bz64_ns16_dime128_dimh128_nl2_epo200_lr0.01_1w.pkl'\n",
    "# pridict_s2s_attention_pipline(model_path, batch_size, num_steps, embed_size, num_hiddens, num_layers, dropout, device, num_examples=num_examples)\n",
    "# # 0.110 atten 32 32 10000\n",
    "# # avg blue:0.281, test num:5000 nmt_eng2fra_s2s_atten_bz64_ns16_dime128_dimh128_nl1_epo200_lr0.01_10w.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch(d2l)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
